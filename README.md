# CoMA: Compositional Human Motion Generation with Multi-modal Agents 
[![Project Page](https://img.shields.io/badge/Project-Page-Green)]([https://gabrie-l.github.io/coma-page/])

> **CoMA: Compositional Human Motion Generation with Multi-modal Agents**
> [Shanlin Sun*]([https://siwensun.github.io/]), [Gabriel De Araujo*]([https://gabrie-l.github.io/]), [Jiaqi Xu*]([https://github.com/FufenNan/]), [Shenghan Zhou*]([https://shenghanzhou.github.io/]), [Hanwen Zhang]([https://github.com/zhw123456789/]), [Ziheng Huang]([https://github.com/HuangZiheng-o-O/]), [Chenyu You]([https://chenyuyou.me/]) and [Xiaohui Xie]([https://ics.uci.edu/~xhx/])
> 
> (\* Equal Contribution)
>
> - Presented by University of California, Irvine; Southeast University; Chongqing University; Huazhong University of Science and Technology; Northeastern University; Stony Brook University
> - :mailbox_with_mail: Primary contact: [Shanlin Sun]([https://siwensun.github.io/]) ( shanlins@uci.edu )
>

## Highlights <a name="highlights"></a>

:star2: **CoMA**, a compositional human motion generation framework with multi-modal agents.

:star2: CoMA can generate high-quality motion sequences given long, complex and context-rich text prompts. 

![](./assets/teaser_v2.png "CoMA")

## ğŸ“° News

## ğŸ“ TODO List

- \[ \] Release CoMA full implementation.
- \[ \] Release MVC training code.
- \[ \] Release SPAM training code.
- \[ \] Release MVC inference code and checkpoints.
- \[ \] Release SPAM inference code and checkpoints.
